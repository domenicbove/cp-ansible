# Maintained by Ansible
{% for key, value in kafka_rest.properties.items() %}
{{key}}={{value}}
{% endfor %}

# Kafka Rest Configuration
listeners={{kafka_rest_http_protocol}}://0.0.0.0:{{kafka_rest_port}}
host.name={{inventory_hostname}}
{% if kafka_rest_ssl_enabled|bool %}
ssl.keystore.location={{kafka_rest_keystore_path}}
ssl.keystore.password={{kafka_rest_keystore_storepass}}
ssl.key.password={{kafka_rest_keystore_keypass}}
{% if kafka_rest_ssl_mutual_auth_enabled|bool %}
ssl.client.auth=false
#Set to true if you wish to force Client SSL Authentication
ssl.truststore.location={{kafka_rest_truststore_path}}
ssl.truststore.password={{kafka_rest_truststore_storepass}}
{% endif %}
{% endif %}

# TODO open up ports to zk
# Mar 07 00:45:35 ip-172-31-33-233.us-west-2.compute.internal kafka-rest-start[15260]: java.lang.IllegalArgumentException: A HostProvider may not be empty!
zookeeper.connect={% for host in groups['zookeeper'] %}{% if loop.index > 1%},{% endif %}{{ host }}:{{zookeeper.properties.clientPort}}{% endfor %}

# Kafka Broker Configuration
bootstrap.servers={% for host in groups['kafka_broker'] %}{% if loop.index > 1%},{% endif %}{{ host }}:{{kafka_broker_listeners[kafka_rest_kafka_listener_name]['port']}}{% endfor %}

client.security.protocol={{kafka_broker_listeners[kafka_rest_kafka_listener_name] | kafka_protocol_defaults(sasl_protocol, ssl_enabled) }}
{% if kafka_broker_listeners[kafka_rest_kafka_listener_name]['ssl_enabled'] | default(ssl_enabled) | bool %}
client.ssl.truststore.location={{kafka_rest_truststore_path}}
client.ssl.truststore.password={{kafka_rest_truststore_storepass}}
{% if kafka_broker_listeners[kafka_rest_kafka_listener_name]['ssl_mutual_auth_enabled'] | default(ssl_mutual_auth_enabled) | bool %}
client.ssl.keystore.location={{kafka_rest_keystore_path}}
client.ssl.keystore.password={{kafka_rest_keystore_storepass}}
client.ssl.key.password={{kafka_rest_keystore_keypass}}
{% endif %}
{% endif %}
{% if kafka_broker_listeners[kafka_rest_kafka_listener_name]['sasl_protocol'] | default(sasl_protocol) | normalize_sasl_protocol == 'PLAIN' %}
client.sasl.mechanism=PLAIN
client.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \
   username="{{sasl_plain_users.kafka_rest.principal}}" password="{{sasl_plain_users.kafka_rest.password}}";
{% endif %}
{% if kafka_broker_listeners[kafka_rest_kafka_listener_name]['sasl_protocol'] | default(sasl_protocol) | normalize_sasl_protocol == 'GSSAPI' %}
client.sasl.mechanism=GSSAPI
client.sasl.kerberos.service.name={{kerberos_kafka_broker_primary}}
client.sasl.jaas.config=com.sun.security.auth.module.Krb5LoginModule required \
   useKeyTab=true \
   storeKey=true \
   keyTab="{{kerberos.keytab_dir}}/{{kafka_rest_kerberos_keytab_path | basename}}" \
   principal="{{kafka_rest_kerberos_principal}}";
{% endif %}
{% if kafka_broker_listeners[kafka_rest_kafka_listener_name]['sasl_protocol'] | default(sasl_protocol) | normalize_sasl_protocol == 'SCRAM-SHA-256' %}
client.sasl.mechanism=SCRAM-SHA-256
client.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required \
  username="{{sasl_scram_users.kafka_rest.principal}}" password="{{sasl_scram_users.kafka_rest.password}}";
{% endif %}

{% set schema_registries = groups.get('schema_registry', []) %}
{% if schema_registries %}
# Schema Registry Configuration
schema.registry.url={% for host in groups['schema_registry'] %}{% if loop.index > 1%},{% endif %}{{ schema_registry_http_protocol }}://{{ host }}:{{ schema_registry_listener_port }}{% endfor %}

{% if schema_registry_ssl_enabled|bool %}
schema.registry.ssl.truststore.location={{kafka_rest_truststore_path}}
schema.registry.ssl.truststore.password={{kafka_rest_truststore_storepass}}
schema.registry.ssl.keystore.location={{kafka_rest_keystore_path}}
schema.registry.ssl.keystore.password={{kafka_rest_keystore_storepass}}
schema.registry.ssl.key.password={{kafka_rest_keystore_keypass}}
{% endif %}
{% endif %}

{% if rbac_enabled|bool %}
################################ OAuth Bearer Token for RBAC ################################
kafka.rest.resource.extension.class=io.confluent.kafkarest.security.KafkaRestSecurityResourceExtension
rest.servlet.initializor.classes=io.confluent.common.security.jetty.initializer.InstallBearerOrBasicSecurityHandler
confluent.metadata.bootstrap.server.urls={% for host in groups['kafka_broker'] %}{% if loop.index > 1%},{% endif %}http://{{ host }}:8090{% endfor %}

public.key.path={{rbac_public_pem_file}}
confluent.metadata.server.urls.max.age.ms=60000
client.confluent.metadata.server.urls.max.age.ms=60000

# Credentials to use with the MDS
confluent.metadata.basic.auth.user.info=kafka_rest:{{rbac_principal_password}}
confluent.metadata.http.auth.credentials.provider=BASIC
{% endif %}
